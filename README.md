NIM_project.py uses Llama 3.1 8b model via API (implementation via NVIDIA NIM, works fast and well), while final_project.py uses Llama 2 local installation (via Ollama, but it was extremly slow).
